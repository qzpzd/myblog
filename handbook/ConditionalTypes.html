<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>深度学习图像分类算法 | qzpzd的博客</title>
    <meta name="generator" content="VuePress 1.9.9">
    <link rel="icon" href="/myblog/ico.png">
    <meta name="description" content="qzpzd的博客">
    
    <link rel="preload" href="/myblog/assets/css/0.styles.28563538.css" as="style"><link rel="preload" href="/myblog/assets/js/app.0a348dd9.js" as="script"><link rel="preload" href="/myblog/assets/js/3.223627e9.js" as="script"><link rel="preload" href="/myblog/assets/js/1.bbec06a8.js" as="script"><link rel="preload" href="/myblog/assets/js/12.bf7ee38e.js" as="script"><link rel="prefetch" href="/myblog/assets/js/10.4b6747fb.js"><link rel="prefetch" href="/myblog/assets/js/11.1ad595e9.js"><link rel="prefetch" href="/myblog/assets/js/13.5a07fe7e.js"><link rel="prefetch" href="/myblog/assets/js/14.5c330b46.js"><link rel="prefetch" href="/myblog/assets/js/15.ffefb9d4.js"><link rel="prefetch" href="/myblog/assets/js/4.6d28ea78.js"><link rel="prefetch" href="/myblog/assets/js/5.e8d6d468.js"><link rel="prefetch" href="/myblog/assets/js/6.05f8c129.js"><link rel="prefetch" href="/myblog/assets/js/7.e4c6cf38.js"><link rel="prefetch" href="/myblog/assets/js/8.58c8e876.js"><link rel="prefetch" href="/myblog/assets/js/9.ca67f2e0.js">
    <link rel="stylesheet" href="/myblog/assets/css/0.styles.28563538.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-7dd95ae2><div data-v-7dd95ae2><div class="password-shadow password-wrapper-out" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>qzpzd的博客</h3> <p class="description" data-v-59e6cb88>qzpzd的博客</p> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2023
      </a></span></div></div> <div class="hide" data-v-7dd95ae2><header class="navbar" data-v-7dd95ae2><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/myblog/" class="home-link router-link-active"><img src="/myblog/ico.png" alt="qzpzd的博客" class="logo"> <span class="site-name">qzpzd的博客</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/myblog/" class="nav-link"><i class="iconfont icon-zhuye"></i>
  首页
</a></div><div class="nav-item"><a href="https://github.com/qzpzd" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont icon-github"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://blog.csdn.net/m0_47709941" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont icon-csdn"></i>
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="/myblog/tags/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tags
</a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-7dd95ae2></div> <aside class="sidebar" data-v-7dd95ae2><div class="personal-info-wrapper" data-v-1fad0c41 data-v-7dd95ae2><img src="/myblog/ico.png" alt="author-avatar" class="personal-img" data-v-1fad0c41> <!----> <div class="num" data-v-1fad0c41><div data-v-1fad0c41><h3 data-v-1fad0c41>4</h3> <h6 data-v-1fad0c41>文章</h6></div> <div data-v-1fad0c41><h3 data-v-1fad0c41>1</h3> <h6 data-v-1fad0c41>标签</h6></div></div> <ul class="social-links" data-v-1fad0c41></ul> <hr data-v-1fad0c41></div> <nav class="nav-links"><div class="nav-item"><a href="/myblog/" class="nav-link"><i class="iconfont icon-zhuye"></i>
  首页
</a></div><div class="nav-item"><a href="https://github.com/qzpzd" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont icon-github"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://blog.csdn.net/m0_47709941" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont icon-csdn"></i>
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="/myblog/tags/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tags
</a></div> <!----></nav> <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><a href="/myblog/" class="sidebar-heading clickable router-link-active open"><span>欢迎学习</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/myblog/" aria-current="page" class="sidebar-link">学前必读</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/myblog/handbook/基于深度学习的图像分类算法" class="sidebar-heading clickable"><span>基础学习</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/myblog/handbook/基于深度学习的图像分类算法.html" class="sidebar-link">深度学习图像分类算法</a></li><li><a href="/myblog/handbook/深度学习经常用到的代码.html" class="sidebar-link">机器学习和深度学习经常用到的代码</a></li></ul></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>深度学习图像分类算法</h3> <!----> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2023
      </a></span></div></div> <div data-v-7dd95ae2><div data-v-7dd95ae2><main class="page" style="padding-right:0;"><section style="display:;"><div class="page-title"><h1 class="title">深度学习图像分类算法</h1> <div data-v-8a445198><i class="iconfont reco-account" data-v-8a445198><span data-v-8a445198>qzpzd</span></i> <i class="iconfont reco-date" data-v-8a445198><span data-v-8a445198>2023/4/15</span></i> <!----> <!----></div></div> <div class="theme-reco-content content__default"><p>图像分类算法</p> <p><code>&lt;!-- more --&gt;</code></p> <h1 id="小卷积核应用-vggnet"><a href="#小卷积核应用-vggnet" class="header-anchor">#</a> 小卷积核应用-VGGNet</h1> <p>利用小卷积核代替大卷积核，感受野不变减少网络的卷积参数量</p> <p><strong>网络结构</strong>
VGGNet的网络结构如下图所示。VGGNet包含很多级别的网络，深度从11层到19层不等，比较常用的是VGGNet-16和VGGNet-19。VGGNet把网络分成了5段，每段都把多个3*3的卷积网络串联在一起，每段卷积后面接一个最大池化层，最后面是3个全连接层和一个softmax层。</p> <p><img src="ico.png" alt="vggnet"></p> <p>原文链接<a href="https://blog.csdn.net/u013181595/article/details/80974210" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/u013181595/article/details/80974210<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h1 id="最优局部稀疏结构-inception"><a href="#最优局部稀疏结构-inception" class="header-anchor">#</a> 最优局部稀疏结构-Inception</h1> <p>以往网络结构通过级联进行堆叠，随着深度的加深容易产生梯度消失，Szegedy提出加深网络的宽度，用1×1、3×3、5×5与最大池化并行方式进行组织，形成一个局部稀疏结构。</p> <p><img src="https://img-blog.csdnimg.cn/bd6680244f0e4bc493328d7f302f6e75.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> <p>inception网络或inception层的作用就是代替人工来确定卷积层中的过滤器类型或者确定是否需要卷积层或者池化层。一个inception模块会将所有的可能叠加起来，这就是inception模块的核心内容。
<img src="https://img-blog.csdnimg.cn/9954364fd5dd46e38269ab56fc7991ce.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述">
通常称中间的层为瓶颈层，也就是最小网络层。我们先缩小网络，然后在扩大 它。通过两张图的对比可以明显看到，采用了1*1的层的计算成本下降了10倍。那么仅仅大幅缩小表示层规模会不会影响神经网络的性能？事实证明，只要合理构建瓶颈层，那么既可以缩小规模，又不会降低性能，从而大量节省了运算。</p> <p>原文链接<a href="https://blog.csdn.net/u010132497/article/details/80060303" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/u010132497/article/details/80060303<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><strong>Inception V1-V4总结：</strong> <strong>Inception V1:</strong>
Inception v1的网络，将1x1，3x3，5x5的conv和3x3的pooling，堆叠在一起，</p> <p>一方面增加了网络的width，</p> <p>另一方面增加了网络对尺度的适应性；</p> <p><strong>Inception V2:</strong>
一方面了加入了BN层，减少了Internal Covariate Shift（内部neuron的数据分布发生变化），使每一层的输出都规范化到一个N(0, 1)的高斯；
另外一方面学习VGG用2个3x3的conv替代inception模块中的5x5，既降低了参数数量，也加速计算；</p> <p><strong>Inception V3:</strong>
v3一个最重要的改进是分解（Factorization），将7x7分解成两个一维的卷积（1x7,7x1），3x3也是一样（1x3,3x1），</p> <p>这样的好处，</p> <p>既可以加速计算（多余的计算能力可以用来加深网络），</p> <p>又可以将1个conv拆成2个conv，使得网络深度进一步增加，增加了网络的非线性，</p> <p>还有值得注意的地方是网络输入从224x224变为了299x299，更加精细设计了35x35/17x17/8x8的模块。</p> <p><strong>Inception V4:</strong>
v4研究了Inception模块结合Residual Connection能不能有改进？</p> <p>发现ResNet的结构可以极大地加速训练，同时性能也有提升，得到一个Inception-ResNet v2网络，</p> <p>同时还设计了一个更深更优化的Inception v4模型，能达到与Inception-ResNet v2相媲美的性能</p> <p><strong>原文链接</strong>：<a href="https://blog.csdn.net/sunflower_sara/article/details/80686658" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/sunflower_sara/article/details/80686658<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h1 id="恒等映射残差单元-resnet"><a href="#恒等映射残差单元-resnet" class="header-anchor">#</a> 恒等映射残差单元-ResNet</h1> <p>ResNet 是在 2015年 由何凯明等几位大神提出，斩获当年ImageNet竞赛中分类任务第一名，目标检测第一名。获得COCO数据集中目标检测第一名，图像分割第一名。</p> <p><strong>残差单元原理</strong>
H(x)= F(x)+x
当网络某一层已经能够提取最佳特征时，后续层试图改变特征x会使得网络的损失变大，为了减少损失使F(x)自动趋于0，此时H(x)= x</p> <div class="language-mermaid extra-class"><pre class="language-mermaid"><code><span class="token keyword">graph</span> LR
输入特征 <span class="token inter-arrow-label"><span class="token arrow-head arrow operator">--</span> <span class="token label property">x</span> <span class="token arrow operator">--&gt;</span></span>1<span class="token text string">(权重层)</span> <span class="token inter-arrow-label"><span class="token arrow-head arrow operator">--</span><span class="token label property">relu</span><span class="token arrow operator">--&gt;</span></span>2<span class="token text string">(权重层)</span><span class="token inter-arrow-label"><span class="token arrow-head arrow operator">--</span> <span class="token label property">Fx</span> <span class="token arrow operator">--&gt;</span></span>+<span class="token text string">(+)</span><span class="token arrow operator">--&gt;</span>H<span class="token text string">[Hx]</span>
输入特征<span class="token arrow operator">--&gt;</span> +<span class="token text string">(+)</span>

</code></pre></div><p><strong>网络结构</strong> <img src="https://img-blog.csdnimg.cn/1031c77f29bb4b168c9751da5a834643.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"> <strong>亮点</strong></p> <p>1.超深的网络结构（超过1000层）。
2.提出residual（残差结构）模块。
3.使用Batch Normalization 加速训练（丢弃dropout）。</p> <p><strong>1.采用残差结构的原因</strong>
1.梯度消失和梯度爆炸
梯度消失：若每一层的误差梯度小于1，反向传播时，网络越深，梯度越趋近于0
梯度爆炸：若每一层的误差梯度大于1，反向传播时，网络越深，梯度越来越大</p> <p><strong>2.退化问题</strong>
随着层数的增加，预测效果反而越来越差。如下图所示
<img src="https://img-blog.csdnimg.cn/882e60772bd449748fb4032d9ca5d7b0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> <h1 id="多层密集连接-densenet"><a href="#多层密集连接-densenet" class="header-anchor">#</a> 多层密集连接-DenseNet</h1> <p>huang等2017年受ResNet启发提出一种更加密集的前馈式跳跃连接，从<strong>特征角度</strong>出发，通过<strong>增加网络信息流的隐性深层监督</strong>和<strong>特征复用</strong>缓解了<strong>梯度消失</strong>的问题，同时<strong>提升模型的性能</strong>。
<img src="https://img-blog.csdnimg.cn/7b5e1f7cf46c4dfebf83a4555951552d.png" alt="在这里插入图片描述">
在同一个Denseblock中要求feature size保持相同大小,在不同Denseblock之间设置transition layers实现Down sampling, 在作者的实验中transition layer由BN + Conv(1×1) ＋2×2 average-pooling组成</p> <p><strong>网络结构</strong> <img src="https://img-blog.csdnimg.cn/ec1bc576b8a14d2f88d9309cee1090fe.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> <p><strong>DenseNet作为另一种拥有较深层数的卷积神经网络,具有如下优点:</strong></p> <p>(1) 相比ResNet拥有更少的参数数量.</p> <p>(2) 旁路加强了特征的重用.</p> <p>(3) 网络更易于训练,并具有一定的正则效果.</p> <p>(4) 缓解了gradient vanishing和model degradation的问题.</p> <p>论文链接：https：//arxiv.org/pdf/1608.06993.pdf</p> <p>代码的github链接：https：//github.com/liuzhuang13/DenseNet</p> <p>MXNet版本代码（有ImageNet预训练模型）：https：  //github.com/miraclewkf/DenseNet</p> <table><thead><tr><th>原文链接</th> <th>https://zhuanlan.zhihu.com/p/43057737</th></tr></thead> <tbody><tr><td>原文链接</td> <td>https://www.jianshu.com/p/8a117f639eef</td></tr></tbody></table> <h1 id="特征通道重标定-senet"><a href="#特征通道重标定-senet" class="header-anchor">#</a> 特征通道重标定-SENet</h1> <p>SENet是ImageNet 2017（ImageNet收官赛）的冠军模型，和ResNet的出现类似，都在很大程度上减小了之前模型的错误率，并且复杂度低，新增参数和计算量小。</p> <p>一个可以嵌入到主干网络的子模块，包括<strong>压缩、激励、和乘积</strong>，可以学习特征通道之间的关系，将每个特征通道对目标任务的重要性转化为可以学习的参数，根据学习到的参数增强有用的特征通道抑制贡献小的特征通道。
<img src="https://img-blog.csdnimg.cn/75317da823f144cdbe41b696dc3aa837.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> <ol><li>Squeeze部分。即为压缩部分，采用一个全局平均池化操作将输入特征图沿着通道维进行压缩，原始feature map的维度为H<em>W</em>C，其中H是高度（Height），W是宽度（width），C是通道数（channel）。Squeeze做的事情是把H<em>W</em>C压缩为1<em>1</em>C，相当于把H<em>W压缩成一维了，实际中一般是用global average pooling实现的。H</em>W压缩成一维后，相当于这一维参数获得了之前H*W全局的视野，感受区域更广。</li> <li>Excitation部分。得到Squeeze的1<em>1</em>C的表示后，加入一个FC全连接层（Fully Connected），对每个通道的重要性进行预测，得到不同channel的重要性大小后再作用（激励）到之前的feature map的对应channel上，再进行后续操作。</li> <li>最后是一个 Reweight 的操作，我们将 Excitation 的输出的权重看做是进过特征选择后的每个特征通道的重要性，然后通过乘法逐通道加权到先前的特征上，完成在通道维度上的对原始特征的重标定。</li></ol> <p><strong>SENet可以应用到残差结构和密集连接结构中</strong> <img src="https://img-blog.csdnimg.cn/c4fc2fd895c64a6f91b97a6254199b9a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> <p>ImageNet分类Top5错误率：</p> <p>2014 GoogLeNet  6.67%</p> <p>2015 ResNet      3.57%</p> <p>2016 ~~~        2.99%</p> <p>2017 SENet       2.25%</p> <table><thead><tr><th>SENet官方Caffe实现：</th> <th>https://github.com/hujie-frank/SENet</th></tr></thead> <tbody><tr><td>PyTorch实现：</td> <td>https://github.com/moskomule/senet.pytorch</td></tr> <tr><td>TensorFlow实现：</td> <td>https://github.com/taki0112/SENet-Tensorflow</td></tr></tbody></table> <p>原文链接：<a href="https://blog.csdn.net/guanxs/article/details/98544872" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/guanxs/article/details/98544872
<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><a href="https://blog.csdn.net/liuweiyuxiang/article/details/84075343" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/liuweiyuxiang/article/details/84075343<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><strong>总结：</strong>
SE模块将注意力机制引入到深度学习中，且SE本身模块不会对本身结构造成影响，只是多出一条分支，仅增加少量参数，降低了模型的错误率。</p> <h1 id="通道压缩与扩展-squeezenet"><a href="#通道压缩与扩展-squeezenet" class="header-anchor">#</a> 通道压缩与扩展-SqueezeNet</h1> <p>伯克利和斯坦福2016年提出的轻量级卷积神经网络，代表模型轻量化的开端</p> <p>主要包括<strong>压缩与扩张</strong></p> <p><strong>压缩</strong></p> <p>利用1×1卷积降维，减少特征图数目，降低模型的参数量</p> <p><strong>扩张</strong></p> <p>利用1×1与3×3卷积进行扩张，还原特征图数量</p> <h1 id="深度可分离卷积-mobilenet"><a href="#深度可分离卷积-mobilenet" class="header-anchor">#</a> 深度可分离卷积-MobileNet</h1> <p>定位优势：移动设备或者嵌入式设备的轻量级网络，相对同样轻量级的SqueezeNet网络，参数两量近似，性能更好。</p> <p>主要分为两部分：<strong>深度通道卷积与逐点卷积</strong></p> <p><strong>深度通道卷积</strong></p> <p>对于来自上一层的多通道特征图，首先将其全部拆分为单个通道的特征图，分别对他们进行单通道卷积，它只对来自上一层的特征图做了尺寸的调整，而通道数没有发生变化
<img src="https://img-blog.csdnimg.cn/e337dcdb495147a580d7fe8f38ef5a2a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_18,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> <p><strong>逐点卷积</strong></p> <p>因为深度卷积没有融合通道间信息，所以需要配合逐点卷积使用。</p> <p>采取卷积核1×1大小，滤波器包含了与上一层通道数（<strong>即深度卷积通道个数</strong>）一样数量的卷积核。相对于通道而言，对每个通道进行整合卷积（<strong>之间是每个通道单独卷积，这里将不同通道利用1×1逐点卷积并进行合并得到特征图</strong>），这又被称之为逐点卷积（Pointwise Convolution）。
<img src="https://img-blog.csdnimg.cn/7a0c21000cc74b0c861d2b66a4edddfc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_18,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"> <strong>常规卷积</strong> <img src="https://img-blog.csdnimg.cn/8134f6e9286d48309ea597872dc41805.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k5pyI5ZOl5qygNjY2,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"> <strong>总结</strong>：</p> <p>常规卷积与深度可分离卷积不同其实在于深度可分离卷积将卷积过程进行了拆分，把特征图通道与卷积核通道卷积拆分出来。</p> <p><strong>具有更少的参数量（<a href="https://www.cnblogs.com/gshang/p/13548561.html" target="_blank" rel="noopener noreferrer">参数量对比<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>）、计算代价</strong></p> <p>参数量计算方式：</p> <p>P=M1* M2* D* D</p> <p>注：M1,M2输入输出特征图数量，D卷积核大小</p></div></section> <footer class="page-edit"><!----> <!----></footer> <!----> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:0;" data-v-b57cc07c data-v-7dd95ae2></ul></div></div></div><div class="global-ui"><!----><!----></div></div>
    <script src="/myblog/assets/js/app.0a348dd9.js" defer></script><script src="/myblog/assets/js/3.223627e9.js" defer></script><script src="/myblog/assets/js/1.bbec06a8.js" defer></script><script src="/myblog/assets/js/12.bf7ee38e.js" defer></script>
  </body>
</html>
